{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# been researching into neo4js and spark GraphX\n",
    "\n",
    "# for now, see whether this dataset is small enough for networkx\n",
    "\n",
    "# also work on normalizing to N2 form\n",
    "\n",
    "# I am beginning with a simple retweet graph (nodes = users, edges = tweet propagation count)\n",
    "\n",
    "db_path = 'data/tweets_GILLUM/gillum_tweets_N1.db'\n",
    "table_name = 'tweets'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "\n",
    "def is_retweet(status):\n",
    "    if status[:2] == 'RT':\n",
    "        return True # todo do a more thorough check on this\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def parse_retweet(status):\n",
    "    # todo error handling\n",
    "    \n",
    "    status_test = status.split('RT')\n",
    "    #print(status_test)\n",
    "    status_test2 = status_test[1].split(':')\n",
    "    #print(status_test2)\n",
    "    status_clean = string.join(status_test2[1:])\n",
    "    source_user = status_test2[0]\n",
    "    source_user = source_user[1:] # omit the leading space (keep the @)\n",
    "    #print(status_clean)\n",
    "    \n",
    "    return (status_clean, source_user)\n",
    "    \n",
    "# todo parse hashtags, parse urls, parse mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the data\n",
    "db = sqlite3.connect(db_path)\n",
    "print('database connected')\n",
    "# cursor method\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the list of users\n",
    "'''\n",
    "start = timer()\n",
    "\n",
    "cursor.execute('SELECT DISTINCT SCREEN_NAME FROM {}'.format(table_name))\n",
    "screen_names = []\n",
    "for item in cursor:\n",
    "    screen_names.append('@' + item[0]) # add the @ for clarity\n",
    "\n",
    "print(len(screen_names))\n",
    "\n",
    "end = timer()\n",
    "print(\"time elapsed: \")\n",
    "print(end - start)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a networkx graph\n",
    "'''\n",
    "start = timer()\n",
    "\n",
    "G_retweet = nx.DiGraph() # todo directed\n",
    "for screen_name in screen_names:\n",
    "    #print(screen_name)\n",
    "    G_retweet.add_node(screen_name) # todo add metadata (friend count, etc) as properties\n",
    "\n",
    "end = timer()\n",
    "print(\"time elapsed: \")\n",
    "print(end - start)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through tweets and add edges where retweets are found\n",
    "\n",
    "G_retweet = nx.DiGraph()\n",
    "\n",
    "start = timer()\n",
    "\n",
    "cursor.execute('SELECT status_text,screen_name FROM {}'.format(table_name))\n",
    "for item in cursor:\n",
    "    \n",
    "    #print(item)\n",
    "    \n",
    "    status = item[0]\n",
    "    screen_name = '@' + item[1] # add the @ character for clarity\n",
    "    if is_retweet(status):\n",
    "        (clean_tweet, source_user) = parse_retweet(status)        \n",
    "        # add an edge to this user from the source_user\n",
    "        \n",
    "        WEIGHT = 1\n",
    "        try:\n",
    "            G_retweet[source_user][screen_name] += WEIGHT\n",
    "        except:\n",
    "            e = (source_user, screen_name, {\"w\":WEIGHT})\n",
    "            G_retweet.add_edge(*e) # add a new edge\n",
    "    #print('')\n",
    "\n",
    "end = timer()\n",
    "print(\"time elapsed: \")\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check - look at the degree distribution\n",
    "\n",
    "in_degree_list = list(G_retweet.in_degree(weight='w').values())\n",
    "out_degree_list = list(G_retweet.out_degree(weight='w').values())\n",
    "print( str(max(out_degree_list)) + \" is the maximum out degree in the network\")\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(in_degree_list)\n",
    "plt.title('in degree')\n",
    "plt.show()\n",
    "\n",
    "plt.figure() # todo plot on a log axis\n",
    "plt.hist(out_degree_list)\n",
    "plt.title('out degree')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate the highest out-degree nodes (influencers)\n",
    "influencers = []\n",
    "THRESH_out = 99.75\n",
    "thresh_out = np.percentile(out_degree_list,THRESH_out)\n",
    "print(thresh_out)\n",
    "for node in G_retweet.nodes():\n",
    "    #print(node)\n",
    "    if G_retweet.out_degree(node,weight='w') > thresh_out:\n",
    "        influencers.append(node)\n",
    "        #print(node)\n",
    "print(len(influencers))    \n",
    "\n",
    "THRESH_in = 99\n",
    "thresh_in = np.percentile(in_degree_list,THRESH_in)\n",
    "# todo isolate the highest in-degree nodes (spammers) and plot in relation to influencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for writable method: https://networkx.github.io/documentation/stable/reference/classes/generated/networkx.DiGraph.subgraph.html \n",
    "options = {'weight': 'w', 'node_color': 'black','node_size': 3,'width': 0.25, 'alpha': 0.5}\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "# Create a subgraph SG based on a (possibly multigraph) G\n",
    "SG = nx.DiGraph()\n",
    "SG.add_nodes_from(influencers)\n",
    "\n",
    "#print(influencers[1:10])\n",
    "for pre in influencers: # since this is small network just brute force it\n",
    "    for post in influencers:\n",
    "        if G_retweet.has_edge(pre,post):\n",
    "            weight = G_retweet[pre][post][\"w\"]\n",
    "            e =  (pre,post,{\"w\":weight})\n",
    "            SG.add_edge(*e) # add a new edge\n",
    "            #print('added edge')\n",
    "       \n",
    "end = timer()\n",
    "print(\"time elapsed: \")\n",
    "print(end - start)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "#nx.draw_random(G_retweet_loudest)\n",
    "nx.draw_spring(SG, **options)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw as eigenvector centrality, for each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
